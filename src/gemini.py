import os
import json
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import (ChatPromptTemplate,
                                    HumanMessagePromptTemplate)

from dotenv import load_dotenv

from pydantic import BaseModel, Field


load_dotenv()


class OutputData(BaseModel):
    answer: str = Field(..., description="The answer generated by Gemini.")
    video_id: int = Field(..., description="The ID of the relevant video.")


if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY")

def get_video_info(path: str='data/video/video_guide.json') -> dict:
    with open(path, "r") as f:
        data = json.load(f)
    return data

def get_video_info_by_id(video_id: int, path: str='data/video/video_guide.json') -> dict:
    with open(path, "r") as f:
        data = json.load(f)
    for item in data:
        
        if int(item["id"]) == int(video_id):
            return item
    return None

def get_gemini_response(prompt: str ) -> str:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    response = llm.invoke(prompt)
    return response

def get_answer_from_gemini(messages) -> str:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )


    prompt = ChatPromptTemplate.from_messages(
        [
            HumanMessagePromptTemplate.from_template(
                f"""
                You are a helpful assistant.自分のことを増本 浩平（ますもと こうへい、1982年7月11日 - ）とだと思っています。神奈川県藤沢市出身の元サッカー選手、サッカー指導者。現役時のポジションはDF、FW。サッカーのことについて詳しく、とても喋りたがりです。
                また、ユーザの質問に対して、関連する動画のIDを必ず一つ答えてください。その時は動画のdesctiptionの元に説明もしてください。例えば、最後に「動画はこちらです！」など。関係するものがない場合は、動画IDとして-1を返してください。
                {{video_info}}

                {{text}}
                """
            )
        ]
    )

    # response = llm.invoke(prompt)

    data = get_video_info()
    video_info = [
        {"video_id": item["id"], "title": item["title"], "description": item["description"]}
        for item in data
    ]

    # print(prompt)    

    chain = prompt | llm.with_structured_output(OutputData)
    response = chain.invoke({"text": messages ,"video_info": video_info})

    return response.answer, 'NoVideo' if response.video_id == -1 else get_video_info_by_id(response.video_id)['url']

if __name__ == "__main__":
    prompt = "PKはどういう時に使うの？"
    print(get_answer_from_gemini(prompt))
    # print(get_video_info_by_id(2))


    # print(get_video_info())